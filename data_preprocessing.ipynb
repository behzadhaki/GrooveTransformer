{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hvo_sequence import midi_to_hvo_sequence\n",
    "from hvo_sequence import ROLAND_REDUCED_MAPPING\n",
    "GROOVE_MAPPING = {f'groove': [x for x in range(128)]}\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import bz2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While preprocessing, we first select those files that:\n",
    "- Have been labeled with genre\n",
    "- Contain the desired instrument (Guitar) and have a Drum instrument\n",
    "- Have a constant 4/4 Time Signature (Consistent with previous iterations of this work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset containing those files with genre annotation and drums\n",
    "dataset_genre_drums_path = 'data/i2dgd/lmd_separated/has_genre/has_drums/'\n",
    "\n",
    "# Desired instrument name (arbitrari)\n",
    "instrument_name = 'guitar'\n",
    "\n",
    "# Regex to select MIDI tracks according to a given instrument class must include \"_[\" followed by the MIDI Class of Instrument. See: https://fmslogo.sourceforge.io/manual/midi-instrument.html\n",
    "instrument_class = '_[Guitar'\n",
    "\n",
    "# Destination file for the processed information\n",
    "preprocessed_data_path = 'data/i2dgd/guitar2drum.bz2pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of files and genre\n",
    "genre_annotation_json_path = 'data\\i2dgd\\lmd_matched_genre.json'\n",
    "\n",
    "# Remove duplicate transcriptions\n",
    "genre_annotation_no_duplicates = pd.read_json(genre_annotation_json_path).drop_duplicates(subset=['trackId'], keep='first').set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_genre_drums_path):\n",
    "    lakh_id = os.path.basename(root)\n",
    "    if lakh_id in genre_annotation_no_duplicates.index:\n",
    "        md = pd.read_csv(os.path.join(root, f\"{lakh_id}.csv\"))\n",
    "        if (md.iloc[:, -2:] == 4).all().all():\n",
    "            genre = genre_annotation_no_duplicates.loc[lakh_id]['genre']\n",
    "            drums = None\n",
    "            instruments = [] \n",
    "            for file in files:\n",
    "                if \"_[Drums]_\" in file:\n",
    "                    drums = os.path.join(root, file)\n",
    "                elif instrument_class in file:\n",
    "                    instruments.append(os.path.join(root, file))\n",
    "            if drums is not None and len(instruments):\n",
    "                file_paths[lakh_id.replace(\".mid\", \"\")] = (drums, instruments, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hvo_sequences(hvo_sequences):\n",
    "    assert all(hvo_seq.hvo.shape == hvo_sequences[0].hvo.shape for hvo_seq in hvo_sequences)\n",
    "\n",
    "    shape = hvo_sequences[0].hvo.shape\n",
    "    merged_arr = np.zeros_like(hvo_sequences[0].hvo)\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        max_val = -np.inf\n",
    "        max_row = None\n",
    "        for hvo_seq in hvo_sequences:\n",
    "            if hvo_seq.hvo[i, 1] > max_val:\n",
    "                max_val = hvo_seq.hvo[i, 1]\n",
    "                max_row = hvo_seq.hvo[i, :]\n",
    "        merged_arr[i, :] = max_row\n",
    "\n",
    "    return merged_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2279/2279 [2:12:04<00:00,  3.48s/it]   \n"
     ]
    }
   ],
   "source": [
    "training_data = {}\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "filenames = []\n",
    "genres = []\n",
    "inputs_hvo_seqs = []\n",
    "outputs_hvo_seqs = []\n",
    "\n",
    "for lakh_id, values in tqdm(file_paths.items()):\n",
    "    drum_path, instrument_paths, genre = values\n",
    "\n",
    "    _2bar_hvo_seqs_drums = []\n",
    "    _2bar_hvo_seqs_drum_grooves = []\n",
    "    _2bar_hvo_seqs_instrument_grooves = []\n",
    "\n",
    "    common_md = {\n",
    "            'style_primary': genre,\n",
    "            'master_id': lakh_id\n",
    "    }\n",
    "\n",
    "    # Drum HVO\n",
    "    drum_hvo = midi_to_hvo_sequence(filename=drum_path, drum_mapping=ROLAND_REDUCED_MAPPING, beat_division_factors=[4])\n",
    "    drum_hvo.metadata['instrument'] = 'drums'\n",
    "    drum_hvo.metadata['midi_path'] = drum_path\n",
    "    drum_hvo.metadata.update(common_md)\n",
    "    # Adjusting lenght to be multiple of 16\n",
    "    drum_n_bars = drum_hvo.number_of_steps / 16\n",
    "    drum_hvo.adjust_length(int(np.round(drum_n_bars) * 16))\n",
    "\n",
    "    # Drum Groove HVO\n",
    "    drum_groove_hvo = midi_to_hvo_sequence(filename=drum_path, drum_mapping=GROOVE_MAPPING, beat_division_factors=[4])\n",
    "    drum_groove_hvo.metadata['instrument'] = 'drums'\n",
    "    drum_groove_hvo.metadata['midi_path'] = drum_path\n",
    "    drum_groove_hvo.metadata.update(common_md)\n",
    "    # Adjusting lenght to be multiple of 16\n",
    "    drum_groove_hvo.adjust_length(int(np.round(drum_n_bars) * 16))\n",
    "\n",
    "    # instrument Grooves HVOs \n",
    "    all_instrument_grooves_hvo = []\n",
    "    for instrument_path in instrument_paths:\n",
    "        instrument_groove_hvo = midi_to_hvo_sequence(filename=instrument_path, drum_mapping=GROOVE_MAPPING, beat_division_factors=[4])\n",
    "        instrument_groove_hvo.metadata['instrument'] = instrument_name\n",
    "        instrument_groove_hvo.metadata.update(common_md)\n",
    "        # Adjusting lenght to be multiple of 16\n",
    "        instrument_groove_hvo.adjust_length(int(np.round(drum_n_bars) * 16))\n",
    "        all_instrument_grooves_hvo.append(instrument_groove_hvo)\n",
    "\n",
    "\n",
    "    # Splitting into 2 bar segments\n",
    "    for w_start in range(int(drum_n_bars)-1):\n",
    "        start_step = int(w_start * 16)\n",
    "        end_step = start_step + 32\n",
    "        \n",
    "        # Drum HVOs\n",
    "        seg_drum_hvo_seq = drum_hvo.copy_empty()\n",
    "        seg_drum_hvo_seq.hvo = drum_hvo.hvo[start_step:end_step]\n",
    "\n",
    "        # Drum Grooves HVOs\n",
    "        seg_drum_groove_hvo_seq = drum_groove_hvo.copy_empty()\n",
    "        seg_drum_groove_hvo_seq.hvo = drum_groove_hvo.hvo[start_step:end_step]\n",
    "\n",
    "        # instrument Grooves HVOs\n",
    "        all_seq_instrument_hvo_seqs = []\n",
    "        for instrument_groove_hvo in all_instrument_grooves_hvo:\n",
    "            seg_instrument_groove_hvo_seq = instrument_groove_hvo.copy_empty()\n",
    "            seg_instrument_groove_hvo_seq.hvo = instrument_groove_hvo.hvo[start_step:end_step]\n",
    "            all_seq_instrument_hvo_seqs.append(seg_instrument_groove_hvo_seq)\n",
    "        # Merging instrument sequences into a single HVO\n",
    "        seg_instrument_groove_hvo_seq = all_seq_instrument_hvo_seqs[0].copy_empty()\n",
    "        seg_instrument_groove_hvo_seq.hvo = merge_hvo_sequences(all_seq_instrument_hvo_seqs)\n",
    "\n",
    "        if np.any(seg_instrument_groove_hvo_seq.hits) and np.any(seg_drum_groove_hvo_seq.hits):\n",
    "            _2bar_hvo_seqs_drums.append(seg_drum_hvo_seq)\n",
    "            _2bar_hvo_seqs_drum_grooves.append(seg_drum_groove_hvo_seq)\n",
    "            _2bar_hvo_seqs_instrument_grooves.append(seg_instrument_groove_hvo_seq)\n",
    "\n",
    "    # Appending data into corresponding lists\n",
    "    for i in range(len(_2bar_hvo_seqs_drums)):\n",
    "        inputs.append(_2bar_hvo_seqs_instrument_grooves[i].hvo)\n",
    "        inputs_hvo_seqs.append(_2bar_hvo_seqs_instrument_grooves[i])\n",
    "        outputs.append(_2bar_hvo_seqs_drum_grooves[i].hvo)\n",
    "        outputs_hvo_seqs.append(_2bar_hvo_seqs_drum_grooves[i])\n",
    "        filenames.append(lakh_id)\n",
    "        genres.append(genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of the data into 80% train - 20% test.\n",
    "\n",
    "assert len(inputs) == len(outputs) == len(genres) == len(inputs_hvo_seqs) == len(outputs_hvo_seqs)\n",
    "\n",
    "indexes = list(range(len(inputs)))\n",
    "\n",
    "train_indexes, test_indexes = train_test_split(indexes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples (2bar sequences): 170283\n",
      "Number of train samples: 136226\n",
      "Number of test samples: 34057\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of samples (2bar sequences): {len(indexes)}\")\n",
    "print(f\"Number of train samples: {len(train_indexes)}\")\n",
    "print(f\"Number of test samples: {len(test_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"train\": {\n",
    "        \"inputs\": [inputs[i] for i in train_indexes],\n",
    "        \"outputs\": [outputs[i] for i in train_indexes],\n",
    "        \"outputs_hvo_seqs\": [outputs_hvo_seqs[i] for i in train_indexes],\n",
    "        \"filenames\": [filenames[i] for i in train_indexes],\n",
    "        \"style_primary\": [genres[i] for i in train_indexes]\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"inputs\": [inputs[i] for i in test_indexes],\n",
    "        \"outputs\": [outputs[i] for i in test_indexes],\n",
    "        \"outputs_hvo_seqs\": [outputs_hvo_seqs[i] for i in test_indexes],\n",
    "        \"filenames\": [filenames[i] for i in test_indexes],\n",
    "        \"style_primary\": [genres[i] for i in test_indexes]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.BZ2File(preprocessed_data_path, 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_path = 'data/i2dgd/guitar2drum.bz2pickle'\n",
    "with bz2.BZ2File(preprocessed_data_path, 'rb') as f:\n",
    "    guitar2drum_data = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GrooveTransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

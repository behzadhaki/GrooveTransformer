{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### In this notebook, we will import the Groove Midi Dataset and process it, and save it for easily being used in our pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# For some reason, tfds import gives an error on the first attempt but works second time around\n",
    "try:                              \n",
    "    import tensorflow_datasets as tfds\n",
    "except:\n",
    "    import tensorflow_datasets as tfds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "console.log('Starting front end url_querystring_target comm target');\n",
       "const comm = Jupyter.notebook.kernel.comm_manager.new_comm('url_querystring_target', {'init': 1});\n",
       "comm.send({'ipyparams_browser_url': window.location.href});\n",
       "console.log('Sent window.location.href on url_querystring_target comm target');\n",
       "\n",
       "comm.on_msg(function(msg) {\n",
       "    console.log(msg.content.data);\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries for processing/loading/storing the dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ipyparams\n",
    "from shutil import copy2\n",
    "\n",
    "# Import libraries for creating/naming folders/files\n",
    "import os, sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### After preprocessing, a zip file will be stored in data/gmd/zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/behzadhaki/miniconda3/envs/magenta/lib/python36.zip',\n",
       " '/Users/behzadhaki/miniconda3/envs/magenta/lib/python3.6',\n",
       " '/Users/behzadhaki/miniconda3/envs/magenta/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/Users/behzadhaki/miniconda3/envs/magenta/lib/python3.6/site-packages',\n",
       " '/Users/behzadhaki/miniconda3/envs/magenta/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/behzadhaki/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                        preprocess_to_HVO_Sequence.ipynb\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/behzadhaki/miniconda3/envs/magenta/lib/python3.6/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Import the HVO_Sequence implementation\n",
    "sys.path.insert(0, \"../..\") # --> unnecessary in future implementations (when package installed via pip)\n",
    "!ls\n",
    "from hvo_sequence.io_helpers import note_sequence_to_hvo_sequence\n",
    "from hvo_sequence.drum_mappings import ROLAND_REDUCED_MAPPING\n",
    "\n",
    "# Import magenta's note_seq \n",
    "import note_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### We have the dataset already available in tensorflow_datasets, so let's load it first\n",
    "\n",
    "\n",
    "#####  NOTE:\n",
    " you can convert midi to note_sequence, two ways:\n",
    " 1. USE magenta.music.midi_to_note_sequence, BUT THIS will GIVE YOU A PICKLING ERROR\n",
    " 2. install note_seq (pip install note_seq) then use note_seq.midi_to_note_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Let's Start With the 2bar-midionly dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train_unprocessed,dataset_train_info = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TRAIN,\n",
    "    try_gcs=True,\n",
    "    with_info=True)\n",
    "\n",
    "dataset_test_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.TEST,\n",
    "    try_gcs=True)\n",
    "\n",
    "dataset_validation_unprocessed = tfds.load(\n",
    "    name=\"groove/2bar-midionly\",\n",
    "    split=tfds.Split.VALIDATION,\n",
    "    try_gcs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NOTE: TF DATASETS ARE PYTHON ITERABLES\n",
    "you can convert the dataset into a list or numpy array:\n",
    "\n",
    "   * List(dataset)\n",
    "   * tfds.as_numpy(dataset)\n",
    "    \n",
    "Lets see how many samples we've got in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # In all three sets, separate entries into individual examples \n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_test  = dataset_test_unprocessed.batch(1)\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "\n",
    "print(\"\\n Number of Examples in Train Set: {}, Test Set: {}, Validation Set: {}\".format(\n",
    "    len(list(dataset_train)), \n",
    "    len(list(dataset_test)), \n",
    "    len(list(dataset_validation)))\n",
    "     ) \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {bpm: (?,), drummer: (?,), id: (?,), midi: (?,), style: {primary: (?,), secondary: (?,)}, time_signature: (?,), type: (?,)}, types: {bpm: tf.int32, drummer: tf.int64, id: tf.string, midi: tf.string, style: {primary: tf.int64, secondary: tf.string}, time_signature: tf.int64, type: tf.int64}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download groovemidi set (midi files and metadata of performances, not chopped files!) \n",
    "### we need this for accessing the metadata file (we won't be )\n",
    "### if you don't want to use wget, download the zipped set from https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip  and extract it in data/gmd/resources/source_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "unzip:  cannot find or open resources/source_dataset/groove-v1.0.0-midionly.zip, resources/source_dataset/groove-v1.0.0-midionly.zip.zip or resources/source_dataset/groove-v1.0.0-midionly.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!mkdir resources\n",
    "!mkdir resources/source_dataset\n",
    "!wget -N -P resources/source_dataset https://storage.googleapis.com/magentadata/datasets/groove/groove-v1.0.0-midionly.zip\n",
    "!unzip -n resources/source_dataset/groove-v1.0.0-midionly.zip -d resources/source_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now, we will start pre-process the downloaded 2-bar groove midi datasets.\n",
    "The metadata for the dataset is not available via the tfds.load() method. As a result, I have manually downloaded the groove-v1.0.0-midionly.zip dataset from here:\n",
    "        \n",
    "        https://magenta.tensorflow.org/datasets/groove\n",
    "        \n",
    "In this folder (currently in resources/source_dataset), there is a csv file containing the metadata for each of the examples. I will match each of the 2-bar examples (downloaded from tfds.load()) with the csv file available in the manually downloaded groove-v1.0.0-midionly.zip\n",
    "\n",
    "\n",
    "To keep track of the metadata, a panda's dataframe with the following fields is used\n",
    "\n",
    "* Keys from Groove MIDI Dataset:\n",
    "    * bpm\n",
    "    * drummer\n",
    "    * id \n",
    "    * midi\n",
    "    * style\n",
    "    * time_signature\n",
    "    * type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/1</td>\n",
       "      <td>funk/groove1</td>\n",
       "      <td>138</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>27.872308</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/10</td>\n",
       "      <td>soul/groove10</td>\n",
       "      <td>102</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>37.691158</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/2</td>\n",
       "      <td>funk/groove2</td>\n",
       "      <td>105</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>36.351218</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/3</td>\n",
       "      <td>soul/groove3</td>\n",
       "      <td>86</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>44.716543</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/4</td>\n",
       "      <td>soul/groove4</td>\n",
       "      <td>80</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>47.987500</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer                session                        id          style  \\\n",
       "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
       "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
       "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
       "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
       "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
       "\n",
       "   bpm beat_type time_signature  \\\n",
       "0  138      beat            4-4   \n",
       "1  102      beat            4-4   \n",
       "2  105      beat            4-4   \n",
       "3   86      beat            4-4   \n",
       "4   80      beat            4-4   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
       "\n",
       "                                      audio_filename   duration split  \n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('resources/source_dataset/groove/info.csv', delimiter = ',')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['drummer1', 'drummer1/eval_session', 'drummer1/eval_session/10',\n",
       "        'soul/groove10', 102, 'beat', '4-4',\n",
       "        'drummer1/eval_session/10_soul-groove10_102_beat_4-4.mid',\n",
       "        'drummer1/eval_session/10_soul-groove10_102_beat_4-4.wav',\n",
       "        37.691158, 'test']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick guide to using the panda dataframe\n",
    "(dataframe[dataframe.id == \"drummer1/eval_session/10\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Difference between tfds.load(name=\"groove/2bar-midionly\") and groove-v1.0.0-midionly.zip\n",
    "\n",
    "In groove-v1.0.0-midionly.zip, we have access to full performances, while using tfds.load(name=\"groove/2bar-midionly\"), we can readily access the performance chopped into 2 bar segments. \n",
    "\n",
    "However, in the pre-chopped set, the meta data is missing. \n",
    "\n",
    "Hence, we need to find the relevant metadata in the info.csv file available groove-v1.0.0-midionly.zip. \n",
    "\n",
    "To do so, we match the beginning of the id in the chopped segments with the id in info.csv\n",
    "\n",
    "\n",
    "# Preprocessing Steps\n",
    "\n",
    "\n",
    "To preprocess the set, we will go through each of the examples in train/test/eval sets and do the following:\n",
    "\n",
    "    1. get the midi file from the \"midi\" field available from tfds.load()\n",
    "    2. convert midi to note_sequence \n",
    "    2. convert the note_sequence to HVO_Sequence\n",
    "    3. get the id from the \"id\" field available from tfds.load()\n",
    "    4. Match the beginning of the \"id\" field with the ids in the pandas dataframe (loaded from groove-v1.0.0-midionly.zip)\n",
    "    5. Store all processed/retrieved fields in a dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dict_append(dictionary, key, vals):\n",
    "    # Appends a value or a list of values to a key in a dictionary\n",
    "    \n",
    "    # if the values for a key are not a list, they are converted to a list and then extended with vals\n",
    "    dictionary[key]=list(dictionary[key]) if not isinstance(dictionary[key], list) else dictionary[key]\n",
    "    \n",
    "    # if vals is a single value (not a list), it's converted to a list so as to be iterable\n",
    "    vals = [vals] if not isinstance(vals, list) else vals\n",
    "        \n",
    "    # append new values \n",
    "    for val in vals:\n",
    "        dictionary[key].append(val)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def convert_groove_midi_dataset(dataset, beat_division_factors=[4], csv_dataframe_info=None):\n",
    "    \n",
    "    dataset_dict_processed = dict()\n",
    "    dataset_dict_processed.update({\n",
    "        \"drummer\":[],\n",
    "        \"session\":[],\n",
    "        \"loop_id\":[],  # the id of the recording from which the loop is extracted\n",
    "        \"master_id\":[], # the id of the recording from which the loop is extracted\n",
    "        \"style_primary\":[],\n",
    "        \"style_secondary\":[],\n",
    "        \"bpm\":[],\n",
    "        \"beat_type\":[],\n",
    "        \"time_signature\":[],\n",
    "        \"full_midi_filename\":[],\n",
    "        \"full_audio_filename\":[],\n",
    "        \"midi\":[],\n",
    "        \"note_sequence\":[],\n",
    "        \"hvo_sequence\":[],\n",
    "    })\n",
    "    \n",
    "    for features in dataset:\n",
    "        \n",
    "        # Features to be extracted from the dataset\n",
    "        \n",
    "        note_sequence = note_seq.midi_to_note_sequence(tfds.as_numpy(features[\"midi\"][0]))\n",
    "        \n",
    "        \n",
    "        if note_sequence.notes: # ignore if no notes in note_sequence (i.e. empty 2 bar sequence)\n",
    "                        \n",
    "            _hvo_seq = note_sequence_to_hvo_sequence(\n",
    "                ns = note_sequence, \n",
    "                drum_mapping = ROLAND_REDUCED_MAPPING,\n",
    "                beat_division_factors = beat_division_factors\n",
    "            )\n",
    "            \n",
    "            \n",
    "            if (not csv_dataframe_info.empty) and len(_hvo_seq.time_signatures)==1 and len(_hvo_seq.tempos)==1 :\n",
    "\n",
    "                # Master ID for the Loop\n",
    "                main_id = features[\"id\"].numpy()[0].decode(\"utf-8\").split(\":\")[0]\n",
    "\n",
    "                # Get the relevant series from the dataframe\n",
    "                df = csv_dataframe_info[csv_dataframe_info.id == main_id]\n",
    "                \n",
    "                # Update the dictionary associated with the metadata\n",
    "                dict_append(dataset_dict_processed, \"drummer\", df[\"drummer\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.drummer = df[\"drummer\"].to_numpy()[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"session\", df[\"session\"].to_numpy()[0].split(\"/\")[-1])\n",
    "                _hvo_seq.metadata.session = df[\"session\"].to_numpy()[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"loop_id\", features[\"id\"].numpy()[0].decode(\"utf-8\"))\n",
    "                _hvo_seq.metadata.loop_id = features[\"id\"].numpy()[0].decode(\"utf-8\")\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"master_id\", main_id)\n",
    "                _hvo_seq.metadata.master_id = main_id\n",
    "\n",
    "                style_full = df[\"style\"].to_numpy()[0]\n",
    "                style_primary = style_full.split(\"/\")[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"style_primary\", style_primary)\n",
    "                _hvo_seq.metadata.style_primary = style_primary\n",
    "\n",
    "                \n",
    "                if \"/\" in style_full:\n",
    "                    style_secondary = style_full.split(\"/\")[1]\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", style_secondary)\n",
    "                    _hvo_seq.metadata.style_secondary = style_secondary\n",
    "                else:\n",
    "                    dict_append(dataset_dict_processed, \"style_secondary\", [\"None\"])\n",
    "                    _hvo_seq.metadata.style_secondary = \"None\"\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"bpm\", df[\"bpm\"].to_numpy()[0])\n",
    "\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"beat_type\", df[\"beat_type\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.beat_type = df[\"beat_type\"].to_numpy()[0]\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"time_signature\", df[\"time_signature\"].to_numpy()[0])\n",
    "                \n",
    "                dict_append(dataset_dict_processed, \"full_midi_filename\", df[\"midi_filename\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.full_midi_filename = df[\"midi_filename\"].to_numpy()[0]\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"full_audio_filename\", df[\"audio_filename\"].to_numpy()[0])\n",
    "                _hvo_seq.metadata.full_audio_filename = df[\"audio_filename\"].to_numpy()[0]\n",
    "\n",
    "                dict_append(dataset_dict_processed, \"midi\", features[\"midi\"].numpy()[0])\n",
    "                dict_append(dataset_dict_processed, \"note_sequence\", [note_sequence])\n",
    "                        \n",
    "                dict_append(dataset_dict_processed, \"hvo_sequence\", _hvo_seq)\n",
    "\n",
    "        else:\n",
    "            pass \n",
    "            \n",
    "    return dataset_dict_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 2.7 s, total: 1min 41s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Process Training Set\n",
    "dataset_train = dataset_train_unprocessed.batch(1)\n",
    "dataset_train_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_train, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe\n",
    ")\n",
    "\n",
    "# Process Test Set\n",
    "dataset_test = dataset_test_unprocessed.batch(1)\n",
    "dataset_test_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_test, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe)\n",
    "\n",
    "# Process Validation Set\n",
    "dataset_validation = dataset_validation_unprocessed.batch(1)\n",
    "dataset_validation_processed = convert_groove_midi_dataset(\n",
    "    dataset = dataset_validation, \n",
    "    beat_division_factors=[4], \n",
    "    csv_dataframe_info=dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Order the pre-processed set\n",
    "The batching process shuffles the dataset. However, we prefer to store the dataset in sequential order. Hence, we need to manually order the dataset. In this tutorial, I order the sequences by loop_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sort_dictionary_by_key (dictionary_to_sort, key_used_to_sort):\n",
    "    # sorts a dictionary according to the list within a given key\n",
    "    sorted_ids=np.argsort(dictionary_to_sort[key_used_to_sort])\n",
    "    for key in dictionary_to_sort.keys():\n",
    "        dictionary_to_sort[key]=[dictionary_to_sort[key][i] for i in sorted_ids]\n",
    "    return dictionary_to_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the sets using ids\n",
    "dataset_train_processed = sort_dictionary_by_key(dataset_train_processed, \"loop_id\")\n",
    "dataset_test_processed = sort_dictionary_by_key(dataset_test_processed, \"loop_id\")\n",
    "dataset_validation_processed = sort_dictionary_by_key(dataset_validation_processed, \"loop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--------------------------------------\n",
    "--------------------------------------\n",
    "\n",
    "# Storing Pre-Processed Sets\n",
    "\n",
    "The folder structure is as follows:\n",
    "\n",
    "./Preprocess_GMD2HVO_Sequence.ipynb\n",
    "\n",
    "./processed_dataset\n",
    "\n",
    "      |\n",
    "      |--> /Processed_On_%d_%m_%Y_at_%H_%M_hrs\n",
    "            |\n",
    "            |--> /GrooveMIDI_processed_{train, test, or validation}\n",
    "                    |\n",
    "                    |--> hvo_sequence.obj\n",
    "                    |\n",
    "                    |--> note_sequence.obj\n",
    "                    |\n",
    "                    |--> midi.obj\n",
    "                    |\n",
    "                    |--> midi.obj\n",
    "                    |\n",
    "                    |--> metadata.csv\n",
    "                    \n",
    "                    \n",
    "The midi files, hvo_sequences and note_sequences along with corresponding metadata are all saved in separate files. The order of entries in all these files match one another (increasing in alpha-numeric order of \"loopid\"s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DUMP INTO A PICKLE FILE\n",
    "def store_dataset_as_pickle(dataset_list, \n",
    "                            filename_list, \n",
    "                            root_dir = \"processed_dataset\",\n",
    "                            append_datetime=True, \n",
    "                            features_with_separate_picklefile = [\"hvo\", \"midi\", \"note_seq\"]\n",
    "                           ):\n",
    "\n",
    "    #filename = filename.split(\".obj\")[0]\n",
    "    path = root_dir\n",
    "    \n",
    "    if append_datetime:\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_at_%H_%M_hrs\")\n",
    "    else:\n",
    "        dt_string =\"\"\n",
    "        \n",
    "    path = os.path.join(path, \"Processed_On_\"+dt_string)\n",
    "    \n",
    "    if not os.path.exists (path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    currentNotebook = ipyparams.notebook_name\n",
    "    print(\"Copying Source Code from %s to %s\" % (os.path.join(os.getcwd(), currentNotebook), path))\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    # copy2(os.path.join(os.getcwd(), currentNotebook), path) \n",
    "    \n",
    "    for i, dataset in enumerate(dataset_list):\n",
    "\n",
    "        subdirectory = os.path.join(path, filename_list[i])\n",
    "        if not os.path.exists (subdirectory):\n",
    "            os.makedirs(subdirectory)\n",
    "            \n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        print(\"Processing %s folder\" % subdirectory)\n",
    "        print(\"-\"*100)\n",
    "        print(\"-\"*100)\n",
    "        \n",
    "        # Create Metadata File\n",
    "        csv_dataframe = pd.DataFrame()\n",
    "        \n",
    "        for k in dataset.keys():\n",
    "            if k not in features_with_separate_picklefile:\n",
    "                csv_dataframe[k] = dataset[k]\n",
    "        \n",
    "        csv_dataframe.to_csv(os.path.join(subdirectory, \"metadata.csv\"))\n",
    "        \n",
    "        print(\"Metadata created!\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        for feature in features_with_separate_picklefile:\n",
    "            if feature in dataset.keys():\n",
    "                dataset_filehandler = open(os.path.join(subdirectory, \"%s_data.obj\"%feature),\"wb\")\n",
    "                print(feature)\n",
    "                print(dataset_filehandler)\n",
    "                pickle.dump(dataset[feature],  dataset_filehandler)\n",
    "                dataset_filehandler.close()\n",
    "                print(\"feature %s pickled at %s\" % (feature, os.path.join(subdirectory, \"%s.obj\"%filename_list[i].split(\".\")[0])))\n",
    "                print(\"-\"*100)\n",
    "\n",
    "            else:\n",
    "                 raise Warning(\"Feature is not available: \", feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Source Code from /Users/behzadhaki/Github/VariationalMonotonicGrooveTransformer/data/gmd/preprocess_to_HVO_Sequence.ipynb to ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train/midi_data.obj'>\n",
      "feature midi pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test/midi_data.obj'>\n",
      "feature midi pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation/midi_data.obj'>\n",
      "feature midi pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at ../processed_dataset/Processed_On_02_10_2022_at_09_06_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_list = [dataset_train_processed,\n",
    "               dataset_test_processed,\n",
    "               dataset_validation_processed]\n",
    "\n",
    "filename_list = [\"GrooveMIDI_processed_train\",\n",
    "                \"GrooveMIDI_processed_test\",\n",
    "                \"GrooveMIDI_processed_validation\"]\n",
    "\n",
    "store_dataset_as_pickle(dataset_list, \n",
    "                        filename_list,\n",
    "                        root_dir=\"../processed_dataset\",\n",
    "                        append_datetime=True,\n",
    "                        features_with_separate_picklefile = [\"hvo_sequence\", \"midi\", \"note_sequence\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Source Code from /Users/behzadhaki/Documents/School Work (Stored on Catalina and Mega Only)/GMD2HVO_PreProcessing/ to processed_dataset/Processed_On_14_06_2021_at_14_26_hrs\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train/midi_data.obj'>\n",
      "feature midi pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_train/GrooveMIDI_processed_train.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test/midi_data.obj'>\n",
      "feature midi pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_test/GrooveMIDI_processed_test.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation folder\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Metadata created!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hvo_sequence\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation/hvo_sequence_data.obj'>\n",
      "feature hvo_sequence pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "midi\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation/midi_data.obj'>\n",
      "feature midi pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n",
      "note_sequence\n",
      "<_io.BufferedWriter name='processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation/note_sequence_data.obj'>\n",
      "feature note_sequence pickled at processed_dataset/Processed_On_14_06_2021_at_14_26_hrs/GrooveMIDI_processed_validation/GrooveMIDI_processed_validation.obj\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_list = [dataset_train_processed,\n",
    "               dataset_test_processed,\n",
    "               dataset_validation_processed]\n",
    "\n",
    "filename_list = [\"GrooveMIDI_processed_train\",\n",
    "                \"GrooveMIDI_processed_test\",\n",
    "                \"GrooveMIDI_processed_validation\"]\n",
    "\n",
    "store_dataset_as_pickle(dataset_list, \n",
    "                        filename_list,\n",
    "                        root_dir=\"processed_dataset\",\n",
    "                        append_datetime=True,\n",
    "                        features_with_separate_picklefile = [\"hvo_sequence\", \"midi\", \"note_sequence\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---------\n",
    "----------\n",
    "\n",
    "### Using Pre-Processed Sets After Storing\n",
    "\n",
    "Now, we can import the pre-processed sets easily into our scripts without going through this procedure. \n",
    "\n",
    "To do so, load the pickle files and the metadata from corresponding subfolders!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_dataset/Processed_On_16_05_2021_at_11_06_hrs/GrooveMIDI_processed_train/hvo_data.obj\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processed_dataset/Processed_On_16_05_2021_at_11_06_hrs/GrooveMIDI_processed_train/hvo_sequence_data.obj'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-98ab7a46b650>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0msource_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"processed_dataset/Processed_On_16_05_2021_at_11_06_hrs\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"GrooveMIDI_processed_train\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"hvo_data.obj\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mtrain_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"GrooveMIDI_processed_train\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"hvo_sequence_data.obj\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mtrain_set\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmetadata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"GrooveMIDI_processed_train\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"metadata.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'processed_dataset/Processed_On_16_05_2021_at_11_06_hrs/GrooveMIDI_processed_train/hvo_sequence_data.obj'"
     ]
    }
   ],
   "source": [
    "source_path = \"processed_dataset/Processed_On_16_05_2021_at_11_06_hrs\"\n",
    "print(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_data.obj\"))\n",
    "train_file = open(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"hvo_sequence_data.obj\"),'rb')\n",
    "train_set = pickle.load(train_file)\n",
    "metadata = pd.read_csv(os.path.join(source_path, \"GrooveMIDI_processed_train\", \"metadata.csv\"))\n",
    "\n",
    "features_in_metadata = list(metadata.columns)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "\n",
    "print(\"Dataset Size: %d \\n Features: \" % dataset_size, features_in_metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hvo_seq = train_set[102]\n",
    "hvo_seq.time_signatures\n",
    "hvo_seq.hvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Let's look at a random entry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ix =  int(np.random.random_sample()*dataset_size)\n",
    "print(\"Sample Number: %d, Primary Style: %s, Secondary Style: %s\" % (ix, \n",
    "                                                                     metadata[\"style_secondary\"][ix], \n",
    "                                                                     metadata[\"style_primary\"][ix])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = train_set[ix].to_html_plot(filename=\"pre_processing_tutorial/misc/temp.html\")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filters = {\n",
    "    \"drummer\": None,               # [\"drummer1\", ..., and/or \"session9\"]\n",
    "    \"session\": None,               # [\"session1\", \"session2\", and/or \"session3\"]\n",
    "    \"loop_id\": None,\n",
    "    \"master_id\": None,\n",
    "    \"style_primary\": None,        # [funk, latin, jazz, rock, gospel, punk, hiphop, pop, soul, neworleans, afrobeat]\n",
    "    #\"style_secondary\" None,       # [fast, brazilian_baiao, funk, halftime, purdieshuffle, None, samba, chacarera, bomba, brazilian, brazilian_sambareggae, brazilian_samba, venezuelan_joropo, brazilian_frevo, fusion, motownsoft]\n",
    "    \"bpm\": None,                  # [(range_0_lower_bound, range_0_upper_bound), ..., (range_n_lower_bound, range_n_upper_bound)]\n",
    "    \"beat_type\": [\"beat\"],        # [\"beat\" or \"fill\"]\n",
    "    \"time_signature\": [\"4-4\"],    # [\"4-4\", \"3-4\", \"6-8\"]\n",
    "    \"full_midi_filename\": None,   # list_of full_midi_filenames\n",
    "    \"full_audio_filename\": None   # list_of full_audio_filename\n",
    "}\n",
    "\n",
    "def check_if_passes_filters(df_row, filters):\n",
    "    meets_filter = []\n",
    "    for filter_key, filter_values in zip(filters.keys(), filters.values()):\n",
    "        if filters[filter_key] is not None:\n",
    "            if df_row.at[filter_key] in filter_values:\n",
    "                meets_filter.append(True)\n",
    "            else:\n",
    "                meets_filter.append(False)\n",
    "    return all(meets_filter)\n",
    "    \n",
    "\n",
    "class GrooveMidiDataset(Dataset):\n",
    "    def __init__(self, source_path = \"processed_dataset/Processed_On_05_05_2021_at_01_09_hrs\", \n",
    "                 subset = \"GrooveMIDI_processed_train\",\n",
    "                 metadata_csv_filename = \"metadata.csv\", \n",
    "                 hvo_pickle_filename = \"hvo_sequence_data.obj\", \n",
    "                 filters = filters):\n",
    "        \n",
    "        train_file = open(os.path.join(source_path, subset, hvo_pickle_filename),'rb')\n",
    "        train_set = pickle.load(train_file)\n",
    "        metadata = pd.read_csv(os.path.join(source_path, subset, metadata_csv_filename))\n",
    "\n",
    "        features_in_metadata = list(metadata.columns)\n",
    "        \n",
    "        self.hvo_sequences = []\n",
    "        for ix, hvo_seq in enumerate(train_set):\n",
    "            if check_if_passes_filters(metadata.loc[ix], filters):\n",
    "                # add metadata to hvo_seq scores\n",
    "                hvo_seq.drummer = metadata.loc[ix].at[\"drummer\"]\n",
    "                hvo_seq.session = metadata.loc[ix].at[\"session\"]\n",
    "                hvo_seq.master_id = metadata.loc[ix].at[\"master_id\"]\n",
    "                hvo_seq.style_primary = metadata.loc[ix].at[\"style_primary\"]\n",
    "                hvo_seq.style_secondary = metadata.loc[ix].at[\"style_secondary\"]\n",
    "                hvo_seq.beat_type = metadata.loc[ix].at[\"beat_type\"]\n",
    "                self.hvo_sequences.append(hvo_seq)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hvo_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.hvo_sequences.hvo, idx\n",
    "        \n",
    "        \n",
    "filters_rock = deepcopy(filters)\n",
    "filters_rock[\"style_primary\"]=[\"rock\"]\n",
    "filters_funk = deepcopy(filters)\n",
    "filters_funk[\"style_primary\"]=[\"funk\"]\n",
    "\n",
    "train_set_rock = GrooveMidiDataset(filters = filters_rock)\n",
    "train_set_funk = GrooveMidiDataset(filters = filters_funk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(train_set_rock.hvo_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(train_set_funk.hvo_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set_rock.hvo_sequences[0].session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filter_a[\"style_primary\"]=[\"rock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filter_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magenta",
   "language": "python",
   "name": "magenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}